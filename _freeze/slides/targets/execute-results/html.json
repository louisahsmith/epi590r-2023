{
  "hash": "d584e27e033641ab76480f34af6c598f",
  "result": {
    "markdown": "---\ntitle: \"{targets}\"\nformat: revealjs\n---\n\n\n## What is `{targets}`?\n\n::: {style=\"height: 0px;\"}\n\n::: {.cell}\n\n:::\n\n\n:::\n\n::: columns\n::: {.column width=\"50%\"}\n![](https://github.com/ropensci/targets/blob/main/man/figures/logo.png?raw=true)\n:::\n\n::: {.column width=\"50%\"}\n\"a Make-like pipeline tool for statistics and data science in R\"\n\n-   manage a sequence of computational steps\n-   only update what needs updating\n-   ensure that the results at the end of the pipeline are still valid\n:::\n:::\n\n## Script-based workflow {.smaller}\n\n`01-data.R`\n\n``` r\nlibrary(tidyverse)\ndata <- read_csv(\"data.csv\", col_types = cols()) %>% \n    filter(!is.na(Ozone))\nwrite_rds(data, \"data.rds\")\n```\n\n`02-model.R`\n\n``` r\nlibrary(tidyverse)\ndata <- read_rds(\"data.rds\")\nmodel <- lm(Ozone ~ Temp, data) %>% \n    coefficients()\nwrite_rds(model, \"model.rds\")\n```\n\n`03-plot.R`\n\n``` r\nlibrary(tidyverse)\nmodel <- read_rds(\"model.rds\")\ndata <- read_rds(\"data.rds\")\nggplot(data) +\n    geom_point(aes(x = Temp, y = Ozone)) +\n    geom_abline(intercept = model[1], slope = model[2])\nggsave(\"plot.png\", plot)\n```\n\n::: aside\nBased on example in <https://books.ropensci.org/targets>\n:::\n\n## Problems with script-based workflow\n\n-   **Reproducibility**: if you change something in one script, you have to remember to re-run the scripts that depend on it\n-   **Efficiency**: that means you'll usually rerun all the scripts even if they don't depend on the change\n-   **Scalability**: if you have a lot of scripts, it's hard to keep track of which ones depend on which\n-   **File management**: you have to keep track of which files are inputs and which are outputs and where they're saved\n\n## \\# `{targets}`: The basics\n\n\n{{< video https://vimeo.com/700982360 width=\"100%\" height=\"100%\" >}}\n\n\n\n## `{targets}` workflow\n\n`R/functions.R`\n\n``` r\nget_data <- function(file) {\n  read_csv(file, col_types = cols()) %>%\n    filter(!is.na(Ozone))\n}\n\nfit_model <- function(data) {\n  lm(Ozone ~ Temp, data) %>%\n    coefficients()\n}\n\nplot_model <- function(model, data) {\n  ggplot(data) +\n    geom_point(aes(x = Temp, y = Ozone)) +\n    geom_abline(intercept = model[1], slope = model[2])\n}\n```\n\n## `{targets}` workflow\n\n`_targets.R`\n\n``` r\nlibrary(targets)\n\ntar_source()\ntar_option_set(packages = c(\"tidyverse\"))\n\nlist(\n  tar_target(file, \"data.csv\", format = \"file\"),\n  tar_target(data, get_data(file)),\n  tar_target(model, fit_model(data)),\n  tar_target(plot, plot_model(model, data))\n)\n```\n\nRun `tar_make()` to run pipeline\n\n::: callout-tip\n`use_targets()` will generate a `_targets.R` script for you to fill in.\n:::\n\n## `{targets}` workflow\n\nTargets are \"hidden\" away where you don't need to manage them\n\n```         \n├── _targets.R\n├── data.csv\n├── R/\n│   ├── functions.R\n├── _targets/\n│   ├── objects\n│          ├── data\n│          ├── model\n│          ├── plot\n```\n\n::: callout-tip\nYou can of course have multiple files in `R/`; `tar_source()` will source them all\n:::\n\n## My typical workflow with `{targets}`\n\n::: smaller\n1.  Read in some data and do some cleaning until it's in the form I want to work with.\n2.  Wrap that in a function and save the file in `R/`.\n3.  Run `use_targets()` and edit `_targets.R` accordingly, so that I list the data file as a target and `clean_data` as the output of the cleaning function.\n4.  Run `tar_make()`.\n5.  Run `tar_load(clean_data)` so that I can work on the next step of my workflow.\n6.  Add the next function and corresponding target when I've solidified that step.\n:::\n\n::: callout-tip\nI usually include `library(targets)` in my project `.Rprofile` so that I can always call `tar_load()` on the fly\n:::\n\n## `_targets.R` tips and tricks\n\n``` r\nlist(\n  tar_target(\n    data_file,\n    \"data/raw_data.csv\",\n    format = \"file\"\n  ),\n  tar_target(\n    raw_data,\n    read.csv(data_file)\n  ),\n  tar_target(\n    clean_data,\n    clean_data_function(raw_data)\n  )\n)\n```\n\n::: callout-tip\nI like to pair my functions/targets by name so that the workflow is clear to me\n:::\n\n## `_targets.R` tips and tricks\n\n``` r\npreparation <- list(\n  ...,\n  tar_target(\n    clean_data,\n    clean_data_function(raw_data)\n  )\n)\nmodeling <- list(\n  tar_target(\n    linear_model,\n    linear_model_function(clean_data)\n  ),\n  ...\n)\nlist(\n  preparation,\n  modeling\n)\n```\n\n::: smaller\n::: callout-tip\nBy grouping the targets into lists, I can easily comment out chunks of the pipeline to not run the whole thing\n:::\n:::\n\n## `_targets.R` tips and tricks\n\n::: columns\n::: {.column width=\"65.5%\"}\n``` r\n## prepare ----\nprepare <- list(\n  ### cleanData.csv ----\n  tar_target(\n    cleanData.csv,\n    file.path(path_to_data, \n              \"cleanData.csv\"),\n    format = \"file\"\n  ),\n  ### newdat ----\n  tar_target(\n    newdat,\n    read_csv(cleanData.csv, \n             guess_max = 20000)\n  ),\n  ...\n```\n:::\n\n::: {.column width=\"34.5%\"}\n![](img/outline.png)\n:::\n:::\n\n::: callout-tip\nIn big projects, I comment my `_targets.R` file so that I can use the RStudio outline pane to navigate the pipeline ([my buggy function](https://github.com/louisahsmith/louisahstuff/blob/master/R/outline_targets.R))\n:::\n\n## Key `{targets}` functions {.smaller}\n\n-   `use_targets()` gets you started with a `_targets.R` script to fill in\n-   `tar_make()` runs the pipeline and saves the results in `_targets/objects/`\n-   `tar_make_future()` runs the pipeline in parallel[^1]\n-   `tar_load()` loads the results of a target into the global environment\\\n    (e.g., `tar_load(clean_data)`)\n-   `tar_read()` reads the results of a target into the global environment\\\n    (e.g., `dat <- tar_read(clean_data)`)\n-   `tar_visnetwork()` creates a network diagram of the pipeline\n-   `tar_outdated()` checks which targets need to be updated\n-   `tar_prune()` deletes targets that are no longer in `_targets.R`\n-   `tar_destroy()` deletes the `.targets/` directory if you need to burn everything down and start again\n\n[^1]: Note: `{targets}` is moving to a new distributed computing strategy using `{crew}`\n\n# Advanced `{targets}`\n\n## \"target factories\"\n\n![](img/factories.png){.r-stretch}\n\n## `{tarchetypes}`: reports\n\nRender documents that depend on targets loaded with `tar_load()` or `tar_read()`.\n\n-   `tar_render()` renders an R Markdown document\n-   `tar_quarto()` renders a Quarto document (or project)\n\n::: callout-warning\nIt can't detect dependencies like `tar_load(ends_with(\"plot\"))`\n:::\n\n## What does `report.qmd` look like?\n\n````         \n---\ntitle: \"My report\"\n---\n```{{r}}\nlibrary(targets)\ntar_load(results)\ntar_load(plots)\n```\nThere were `r results$n` observations with a mean age of `r results$mean_age`.\n```{{r}}\nlibrary(ggplot2)\nplots$age_plot\n```\n````\n\nBecause `report.qmd` depends on `results` and `plots`, it will only be re-rendered if either of those targets change.\n\n::: callout-tip\nThe `extra_files =` argument can be used to force it to depend on additional non-target files\n:::\n\n## `{tarchetypes}`: branching {.smaller}\n\nUsing data from the National Longitudinal Survey of Youth,\n\n::: columns\n::: {.column width=\"39%\"}\n`_targets.R`\n\n``` r\nlibrary(targets)\nlibrary(tarchetypes)\ntar_source()\n\ntargets_setup <- list(\n  tar_target(\n    csv,\n    \"data/nlsy.csv\",\n    format = \"file\"\n  ),\n  tar_target(\n    dat,\n    readr::read_csv(csv, \n      show_col_types = FALSE)\n  )\n)\n```\n:::\n\n::: {.column width=\"2%\"}\n:::\n\n::: {.column width=\"59%\"}\n`R/functions.R`\n\n``` r\nmodel_function <- function(outcome_var, \n                           sex_val, dat) {\n\n  lm(as.formula(paste(outcome_var, \n      \" ~ age_bir + income + factor(region)\")) ,\n     data = dat, \n     subset = sex == sex_val)\n}\n\ncoef_function <- function(model) {\n  coef(model)[[\"age_bir\"]]\n}\n```\n:::\n:::\n\nwe want to investigate the relationship between age at first birth and hours of sleep on weekdays and weekends among moms and dads separately\n\n## Option 1\n\nCreate (and name) a separate target for each combination of sleep variable (`\"sleep_wkdy\"`, `\"sleep_wknd\"`) and sex (male: `1`, female: `2`):\n\n``` r\ntargets_1 <- list(\n  tar_target(\n    model_1,\n    model_function(outcome_var = \"sleep_wkdy\", sex_val = 1, dat = dat)\n  ),\n  tar_target(\n    coef_1,\n    coef_function(model_1)\n  )\n)\n```\n\n... and so on...\n\n``` r\ntar_read(coef_1)\n```\n\n\n::: {.cell}\n\n:::\n\n\n## Option 2\n\nUse `tarchetypes::tar_map()` to map over the combinations for you (static branching):\n\n``` r\ntargets_2 <- tar_map(\n  values = tidyr::crossing(\n    outcome = c(\"sleep_wkdy\", \"sleep_wknd\"),\n    sex = 1:2\n  ),\n  tar_target(\n    model_2,\n    model_function(outcome_var = outcome, sex_val = sex, dat = dat)\n  ),\n  tar_target(\n    coef_2,\n    coef_function(model_2)\n  )\n)\ntar_load(starts_with(\"coef_2\"))\nc(coef_2_sleep_wkdy_1, coef_2_sleep_wkdy_2, coef_2_sleep_wknd_1, coef_2_sleep_wknd_2)\n```\n\n\n::: {.cell}\n\n:::\n\n\n## Option 2, cont.\n\nUse `tarchetypes::tar_combine()` to combine the results of a call to `tar_map()`:\n\n``` r\ncombined <- tar_combine(\n  combined_coefs_2,\n  targets_2[[\"coef_2\"]],\n  command = vctrs::vec_c(!!!.x),\n)\ntar_read(combined_coefs_2)\n```\n\n\n::: {.cell}\n\n:::\n\n\n`command = vctrs::vec_c(!!!.x)` is the default, but you can supply your own function to combine the results\n\n## Option 3\n\n::: smaller\nUse the `pattern =` argument of `tar_target()` (dynamic branching):\n:::\n\n``` r\ntargets_3 <- list(\n  tar_target(\n    outcome_target,\n    c(\"sleep_wkdy\", \"sleep_wknd\")\n  ),\n  tar_target(\n    sex_target,\n    1:2\n  ),\n  tar_target(\n    model_3,\n    model_function(outcome_var = outcome_target, sex_val = sex_target, dat = dat),\n    pattern = cross(outcome_target, sex_target)\n  ),\n  tar_target(\n    coef_3,\n    coef_function(model_3),\n    pattern = map(model_3)\n  )\n)\ntar_read(coef_3)\n```\n\n\n::: {.cell}\n\n:::\n\n\n## Branching\n\n| **Dynamic**                              | **Static**                                         |\n|--------------------------------|----------------------------------------|\n| Pipeline creates new targets at runtime. | All targets defined in advance.                    |\n| Cryptic target names.                    | Friendly target names.                             |\n| Scales to hundreds of branches.          | Does not scale as easily for tar_visnetwork() etc. |\n| No metaprogramming required.             | Familiarity with metaprogramming is helpful.       |\n\n::: aside\nFrom <https://books.ropensci.org/targets/dynamic.html#branching>\n:::\n\n## Branching\n\n-   The book also has an example of using metaprogramming to map over different functions\n    -   i.e. fit multiple models with the same arguments\n-   Static and dynamic branching can be combined\n    -   e.g. `tar_map(values = ..., tar_target(..., pattern = map(...)))`\n-   Branching can lead to slowdowns in the pipeline (see book for suggestions)\n\n## `{tarchetypes}`: repetition\n\n`tar_rep()` repeats a target multiple times with the same arguments\n\n``` r\ntargets_4 <- list(\n  tar_rep(\n    bootstrap_coefs,\n    dat |>\n      dplyr::slice_sample(prop = 1, replace = TRUE) |>\n      model_function(outcome_var = \"sleep_wkdy\", sex_val = 1, dat = _) |>\n      coef_function(),\n    batches = 10,\n    reps = 10\n  )\n)\n```\n\nThe pipeline gets split into `batches` x `reps` chunks, each with its own random seed\n\n## `{tarchetypes}`: mapping over iterations\n\n``` r\nsensitivity_scenarios <- tibble::tibble(\n  error = c(\"small\", \"medium\", \"large\"),\n  mean = c(1, 2, 3),\n  sd = c(0.5, 0.75, 1)\n)\n```\n\n`tar_map_rep()` repeats a target multiple times with different arguments\n\n``` r\ntargets_5 <- tar_map_rep(\n  sensitivity_analysis,\n  dat |> \n    dplyr::mutate(sleep_wkdy = sleep_wkdy + rnorm(nrow(dat), mean, sd)) |>\n    model_function(outcome_var = \"sleep_wkdy\", sex_val = 1, dat = _) |>\n    coef_function() |> \n    data.frame(coef = _),\n  values = sensitivity_scenarios,\n  batches = 10,\n  reps = 10\n)\n```\n\n## `{tarchetypes}`: mapping over iterations\n\n``` r\ntar_read(sensitivity_analysis) |> head()\n```\n\n\n::: {.cell}\n\n:::\n\n\nIdeal for sensitivity analyses that require multiple iterations of the same pipeline with different parameters\n\n``` r\ntar_read(sensitivity_analysis) |>\n  dplyr::group_by(error) |> \n  dplyr::summarize(q25 = quantile(coef, .25),\n                   median = median(coef),\n                   q75 = quantile(coef, .75))\n```\n\n\n::: {.cell}\n\n:::\n\n\n## Conclusion\n\n-   `{targets}` is a great tool for managing complex workflows\n-   `{tarchetypes}` makes it even more powerful\n-   The [user manual](https://books.ropensci.org/targets/) is a great resource for learning more\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}